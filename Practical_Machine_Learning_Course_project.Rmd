---
title: "Practical Machine Learning - Coursera Project"
author: "Dwight Kruger"
date: "October 13, 2015"
output: html_document
---

```{r echo=FALSE, message=F, warning=F}
options(warn=-1)            # Turn off warnings in the output
require(randomForest, quietly = TRUE, warn.conflicts = FALSE)
require(dplyr, quietly = TRUE, warn.conflicts = FALSE)
require(corrplot, quietly = TRUE, warn.conflicts = FALSE)
require(caret, quietly = TRUE, warn.conflicts = FALSE)
```

##Introduction##

Using devices such as *Jawbone Up*, *Nike FuelBand*, and *Fitbit* it is now possible to collect a large amount of data about personal activity relatively inexpensively.

The goal of this project is to build a prediction model which predicts the manner in which the participants did the exercise. The data for this project was generously provided by http://groupware.les.inf.puc-rio.br/har.

##Background##

One thing that people regularly do is quantify *how much* of a particular activity they do, but they rarely quantify *how well* they do it. In this project, the goal will be to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants and predict how well they did the excercise. Training data was obtained from subjects who were asked to perform barbell lifts correctly and incorrectly in 5 different ways. our model will predict which of the 5 classes each subject belongs to. 

More information is available from the website here: http://groupware.les.inf.puc-rio.br/har (see the section on the Weight Lifting Exercise Dataset). A data dictionary can be found at http://groupware.les.inf.puc-rio.br/public/papers/2013.Velloso.QAR-WLE.pdf. Briefly the trainintg set contains a column called *classe* whose values are defined as follows:

- Class A - Exactly according to specification. 
- Class B - Throwing the Elbow to the front. 
- Class C - Lifting the Dumbbell only halfway. 
- Class D - Lowering the Dumbbell only halfway. 
- Class E - Throwing the Hips to the front.

The training data is from https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv

The test data is from https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv

```{r, echo=FALSE}
# The variable 'classe' in the training set describes the activity of the participant: specifically 
#
#   - exactly according to the specification (Class A), 
#   - throwing the elbows to the front (Class B), 
#   - lifting the dumbbell only halfway (Class C), 
#   - lowering the dumbbell only halfway (Class D) and 
#   - throwing the hips to the front (Class E)

# We need to perform some exploritory data analysis to determine which variables are interesting and relevent.
#
# We need to build a model which predicts which of the 5 classes they are in based on the other variables. A random forest with
# bagging seems like a good starting point.
```

##Exploratory Analysis##

Browsing the training data and the data dictionary it is clear that some data will not be useful when building models (subject's name, row identifier, etc.) First we will pre process the training data and remove summary rows as well as all columns for which all data is NA, contain the row identifier, the subject's name, date/time values and window identifiers.

```{r}
# Load the data. 
if (!file.exists("./data")) 
{ 
  dir.create("./data")

  trainingDataUrl <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
  testDataUrl <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"

  download.file(trainingDataUrl, destfile="./data/trainingData.csv", method="auto")
  download.file(testDataUrl, destfile="./data/testData.csv", method="auto")
}

trainingData = read.csv("./data/trainingData.csv", na.strings=c("", "NA", "NULL"))
testData = read.csv("./data/testData.csv", na.strings=c("", "NA", "NULL"))

# Remove irrelevant rows and columns. 
trainingData <- trainingData[trainingData$new_window != "yes",] # Ignore summary rows
trainingData <- trainingData[,colSums(is.na(trainingData)) < nrow(trainingData)]  # Remove NA columns
trainingData <- select(trainingData, -X)                      # Select all except X
trainingData <- select(trainingData, -raw_timestamp_part_1)   # Select all except raw_timestamp_part_1
trainingData <- select(trainingData, -raw_timestamp_part_2)   # Select all except raw_timestamp_part_2
trainingData <- select(trainingData, -cvtd_timestamp)         # Select all except cvtd_timestamp
trainingData <- select(trainingData, -new_window)             # Select all except new_window
trainingData <- select(trainingData, -num_window)             # Select all except num_window
trainingData <- select(trainingData, -user_name)              # Select all except user_name
```
Look for variables in the training set which have near zero variance, i.e. those which have basically the same value for all measurements for all subjects. If we find any, we will want to also remove those variables as well from our training set.

```{r}
countZeroVar <- nearZeroVar(trainingData)
if (any(countZeroVar)) 
  message("Some variables have near zero variance") else 
  message("None of the variables have a near zero variance") 
```
Split the training data into a training set (75%) and a test set (25%)

```{r}
inTrain <- createDataPartition(y=trainingData$classe, p=0.75, list=FALSE)
training <- trainingData[inTrain,]
testing <- trainingData[-inTrain,]
```
We may have variables which are highly correlated with eachother and hence may lead to overfitting. A visualization of the correlation between each pair of variables is given in figure 1 in the appendix figure 1.

##Build the random forest model##
Using Principal Component Analysis (PCA) we will choose the most useful predictors and build a random forest.

```{r}
prComp <- preProcess(training[-53], method="pca", thresh = 0.95)    # PCA to find useful predictors
trainPC <- predict(prComp, training[-53])
rfModel <- randomForest(training$classe ~ ., data=trainPC, importance=TRUE) # Build the random forest
```
Run the test dataset through the prediction model and create a confusion matrix to examine how well the random forest predicted the correct outcomes.

```{r}
predTestData <- predict(rfModel,  predict(prComp, testing[,-53]))
cmTestData <- confusionMatrix(testing$classe, predTestData)
cmTestData$table
```
Calculate the accuracy of our results, by counting the number of times we predicted correctly.
```{r}
accuracy <- postResample(testing$classe, predTestData)
```
The random forest model predicted `r round(accuracy[[1]]*100,2)`% of the time correctly.

## Predict *classe* of the 20 subjects in the test data## 
Finally predict the outcome of our 20 test subjects and write the results to disk.
```{r}
classe_prediction <- predict(rfModel, predict(prComp, testData))
result <- cbind(testData[2], classe_prediction)

mappingTable <- NULL
mappingTable <- rbind(mappingTable, cbind("A", "Exactly according to the specification"))
mappingTable <- rbind(mappingTable, cbind("B", "Throwing the elbows to the front"))
mappingTable <- rbind(mappingTable, cbind("C", "Lifting the dumbbell only halfway"))
mappingTable <- rbind(mappingTable, cbind("D", "Lowering the dumbbell only halfway"))
mappingTable <- rbind(mappingTable, cbind("E", "Throwing the hips to the front"))

foo <- merge(result, mappingTable, by.x = "classe_prediction", by.y="V1")

pml_write_files = function(x){
  n = length(x)
  for(i in 1:n){
    filename = paste0("problem_id_",i,".txt")
    write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
  }
}


pml_write_files(classe_prediction)
```
\newpage
## Appendix ##

**Figure 1:** Correlations between pairs of variables in our training set.

```{r echo=FALSE}
corTable <- cor(training[, -53])
corrplot(corTable, method = "color", tl.cex = 0.5, tl.col = "black", type = "lower", order = "FPC")
```

The darker colors indicate features which are correlated with each other, where blue is a positive correlation and red is a negative correlation. Clearly not all of the variables are necessary since some are highly correlated with eachother.  
