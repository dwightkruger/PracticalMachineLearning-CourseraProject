---
title: "Practical Machine Learning - Coursera Project"
author: "Dwight Kruger"
date: "October 13, 2015"
output: html_document
---

```{r echo=FALSE, message=F, warning=F}
options(warn=-1)            # Turn off warnings in the output
require(randomForest, quietly = TRUE, warn.conflicts = FALSE)
require(dplyr, quietly = TRUE, warn.conflicts = FALSE)
require(corrplot, quietly = TRUE, warn.conflicts = FALSE)
require(caret, quietly = TRUE, warn.conflicts = FALSE)
```

##Introduction##

Using devices such as *Jawbone Up*, *Nike FuelBand*, and *Fitbit* it is now possible to collect a large amount of data about personal activity relatively inexpensively.

The goal of this project is to build a prediction model which predicts the manner in which the participants did the exercise. The data for this project was generously provided by http://groupware.les.inf.puc-rio.br/har.

##Background##

Although people regularly quantify *how much* of a particular activity they do, they rarely quantify *how well* they do it. In this project, the goal will be to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants and predict how well they did the excercise. Training data was obtained from subjects who were asked to perform barbell lifts correctly and incorrectly in 5 different ways. Our model will predict which of the 5 classes each subject belongs to. 

More information is available from the website at: http://groupware.les.inf.puc-rio.br/har (see the section on the Weight Lifting Exercise Dataset). A data dictionary can be found at http://groupware.les.inf.puc-rio.br/public/papers/2013.Velloso.QAR-WLE.pdf. The training set contains a variable called *classe* whose values are defined as follows:

- A - Exactly according to specification. 
- B - Throwing the Elbow to the front. 
- C - Lifting the Dumbbell only halfway. 
- D - Lowering the Dumbbell only halfway. 
- E - Throwing the Hips to the front.

The training data is from https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv

The test data is from https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv

```{r, echo=FALSE}
# The variable 'classe' in the training set describes the activity of the participant: specifically 
#
#   - exactly according to the specification (Class A), 
#   - throwing the elbows to the front (Class B), 
#   - lifting the dumbbell only halfway (Class C), 
#   - lowering the dumbbell only halfway (Class D) and 
#   - throwing the hips to the front (Class E)

# We need to perform some exploritory data analysis to determine which variables are interesting and relevent.
#
# We need to build a model which predicts which of the 5 classes they are in based on the other variables. A random forest with
# bagging seems like a good starting point.
```

##Exploratory Analysis##

Browsing the training data and the data dictionary it is clear that some data will not be useful when building models (such as the subject's name, row identifier, etc.). First we will preprocess the training data and remove clealy irrelevant data such as summary rows as well as columns for which all data is NA, the row identifier, the subject's name, date/time values and window identifiers.

```{r}
# Load the data. 
if (!file.exists("./data")) 
{ 
  dir.create("./data")

  trainingDataUrl <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
  testDataUrl <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"

  download.file(trainingDataUrl, destfile="./data/trainingData.csv", method="auto")
  download.file(testDataUrl, destfile="./data/testData.csv", method="auto")
}

trainingData = read.csv("./data/trainingData.csv", na.strings=c("", "NA", "NULL"))
testData = read.csv("./data/testData.csv", na.strings=c("", "NA", "NULL"))

# Remove irrelevant rows and columns. 
trainingData <- trainingData[trainingData$new_window != "yes",] # Ignore summary rows
trainingData <- trainingData[,colSums(is.na(trainingData)) < nrow(trainingData)]  # Remove NA columns
trainingData <- select(trainingData, -X)                      # Remove X column
trainingData <- select(trainingData, -raw_timestamp_part_1)   # Remove raw_timestamp_part_1 column
trainingData <- select(trainingData, -raw_timestamp_part_2)   # Remove raw_timestamp_part_2 column
trainingData <- select(trainingData, -cvtd_timestamp)         # Remove cvtd_timestamp column
trainingData <- select(trainingData, -new_window)             # Remove new_window column
trainingData <- select(trainingData, -num_window)             # Remove num_window column
trainingData <- select(trainingData, -user_name)              # Remove user_name column
```
Next, we will to look for variables in the training set which have near zero variance, i.e. those which have basically the same value for all measurements for all subjects. If we find any, we will want to also remove those variables as well from our training set.

```{r}
countZeroVar <- nearZeroVar(trainingData)
if (any(countZeroVar)) 
  message("Some variables have near zero variance.") else 
  message("None of the variables have a near zero variance.") 
```
Split the training data into a training set (75%) and a test set (25%)

```{r}
inTrain <- createDataPartition(y=trainingData$classe, p=0.75, list=FALSE)
training <- trainingData[inTrain,]
testing <- trainingData[-inTrain,]
```
We may have variables which are highly correlated with each other and hence may lead to overfitting. A visualization of the correlation between each pair of variables is given in figure 1 in the appendix figure 1.

##Build the Random Forest model##
Using Principal Component Analysis (PCA) we will choose the most useful predictors and build a random forest model.

```{r}
prComp <- preProcess(training[-53], method="pca", thresh = 0.99)    # PCA to find useful predictors
trainPC <- predict(prComp, training[-53])
rfModel <- randomForest(training$classe ~ ., data=trainPC, importance=TRUE) # Build the random forest
```
Run the test set through the prediction model and create a confusion matrix to examine how well the random forest predicted the correct outcomes. This will dermine the cross-validation error.

```{r}
predTestData <- predict(rfModel,  predict(prComp, testing[,-53]))
cmTestData <- confusionMatrix(testing$classe, predTestData)
cmTestData$table
```
Calculate the accuracy of our results, by counting the number of times the model correctly predicted *classe* (accuracy), and the out of sample error. I would be satistifed with a out of sample error of 5% or less.
```{r}
accuracy <- cmTestData$overall[1]
classeAccuracy <- accuracy[[1]]
outOfSampleError <- 1 - classeAccuracy
```
The random forest model predicted *classe* `r round(classeAccuracy*100,2)`% of the time correctly (accuracy) and the out of sample error is 1-accuracy = `r round(outOfSampleError*100,2)`%

## Predict *classe* of the subjects in the test data## 
Finally predict the *classe* of the test subjects using the random forest model.
```{r}
classe_prediction <- predict(rfModel, predict(prComp, testData))
result <- cbind(testData[2], classe_prediction) 
```
```{r echo=FALSE}
# Code provided by Coursera instructors
pml_write_files = function(x){
  n = length(x)
  for(i in 1:n){
    filename = paste0("problem_id_",i,".txt")
    write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
  }
}

# Code provided by http://www.r-statistics.com/2012/01/merging-two-data-frame-objects-while-preserving-the-rows-order/
merge.with.order <- function(x,y, ..., sort = T, keep_order)
	{
		# this function works just like merge, only that it adds the option to return the merged data.frame ordered by x (1) or by y (2)
		add.id.column.to.data <- function(DATA)
		{
			data.frame(DATA, id... = seq_len(nrow(DATA)))
		}
		# add.id.column.to.data(data.frame(x = rnorm(5), x2 = rnorm(5)))
		order.by.id...and.remove.it <- function(DATA)
		{
			# gets in a data.frame with the "id..." column.  Orders by it and returns it
			if(!any(colnames(DATA)=="id...")) stop("The function order.by.id...and.remove.it only works with data.frame objects which includes the 'id...' order column")
 
			ss_r <- order(DATA$id...)
			ss_c <- colnames(DATA) != "id..."
			DATA[ss_r, ss_c]
		}
 
		# tmp <- function(x) x==1; 1	# why we must check what to do if it is missing or not...
		# tmp()
 
		if(!missing(keep_order))
		{
			if(keep_order == 1) return(order.by.id...and.remove.it(merge(x=add.id.column.to.data(x),y=y,..., sort = FALSE)))
			if(keep_order == 2) return(order.by.id...and.remove.it(merge(x=x,y=add.id.column.to.data(y),..., sort = FALSE)))
			# if you didn't get "return" by now - issue a warning.
			warning("The function merge.with.order only accepts NULL/1/2 values for the keep_order variable")
		} else {return(merge(x=x,y=y,..., sort = sort))}
	}

mappingTable <- NULL
mappingTable <- rbind(mappingTable, cbind("A", "Exactly according to the specification"))
mappingTable <- rbind(mappingTable, cbind("B", "Throwing the elbows to the front"))
mappingTable <- rbind(mappingTable, cbind("C", "Lifting the dumbbell only halfway"))
mappingTable <- rbind(mappingTable, cbind("D", "Lowering the dumbbell only halfway"))
mappingTable <- rbind(mappingTable, cbind("E", "Throwing the hips to the front"))
mappingTable <- data.frame(mappingTable)
colnames(mappingTable) <- c("classe_prediction", "Description")

finalResults <- merge.with.order(result, mappingTable, by = "classe_prediction", keep_order=1)[,c(2,1,3)]
row.names(finalResults) <- seq(nrow(finalResults))  # Fix up row numers to be sequential
finalResults

pml_write_files(classe_prediction)
```

## Appendix ##

**Figure 1:** Correlations between pairs of variables in the training set.

```{r echo=FALSE}
corTable <- cor(training[, -53])
corrplot(corTable, method = "color", tl.cex = 0.5, tl.col = "black", type = "lower", order = "FPC")
```

The darker colors indicate features which are correlated with each other, where blue is a positive correlation and red is a negative correlation. Clearly not all of the variables are necessary since some are highly correlated with each other.  
